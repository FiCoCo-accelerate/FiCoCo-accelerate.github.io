<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta property="og:title"
        content="Filter, Correlate, Compress: Training-Free Token Reduction for MLLM Acceleration" />
    <meta property="og:url" content="https://FiCoCo-accelerate.github.io/" />
    <meta property="og:image" content="static/images/head.png" />
    <meta property="og:image:width" content="2048" />
    <meta property="og:image:height" content="1152" />
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>FiCoCo</title>
    <script>
        var x = window.innerWidth;
        function resizeFresh(){
            if(x!=window.innerWidth)
                location.reload();
        }
    </script>
    <link rel="icon" type="image/x-icon" href="static/images/4.png">
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/index.js"></script>
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
</head>

<body onresize="resizeFresh()">

    <section class="hero banner">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">
                            <i class="pixart-alpha-icon"></i>
                            <!-- <span style="color: rgb(167, 175, 246);">SimM:</span> -->
                            <span style="color: rgb(165, 203, 255);">Filter, Correlate, Compress:  </span><br />
                            Training-Free Token Reduction for MLLM Acceleration</h1> 
                        <div class="is-size-5 publication-authors">
                            <!-- Paper authors -->
                            <span class="author-block">
                                <a href="https://scholar.google.com/citations?user=zggQZNAAAAAJ" target="_blank">Yuhang
                                    Han</a><sup>1,â€¡</sup>,</span>
                            <span class="author-block">
                                <a href="https://xuyang-liu16.github.io/" target="_blank">Xuyang
                                    Liu</a><sup>2,â€¡</sup>,</span>
                            <span class="author-block">
                                <a href="" target="_blank">Zihan
                                    Zhang</a><sup>3</sup>,</span>
                            <span class="author-block">
                                <a href="https://dingpx.github.io/" target="_blank">Pengxiang
                                    Ding</a><sup>4</sup>,</span>
                            <span class="author-block">
                                <a href="https://milab.westlake.edu.cn/" target="_blank">Donglin
                                    Wang</a><sup>4</sup>,</span>                                    
                            <span class="author-block">
                                <a href="https://scholar.google.com/citations?user=qkpb0CMAAAAJ" target="_blank">
                                    Honggang
                                    Chen</a><sup>2</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://qingsenyangit.github.io/" target="_blank">
                                    Qingsen 
                                    Yan</a><sup>1</sup></span>
                            <span class="author-block">
                                <a href="https://kyonhuang.top/" target="_blank">
                                    Siteng 
                                    Huang</a><sup>5,*</sup></span>                  
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block"><sup>1</sup>Northwestern Polytechnical University</span>&nbsp;&nbsp;<span class="author-block"><sup>2</sup>Sichuan University</span>&nbsp;&nbsp;<span class="author-block"><sup>3</sup>Johns Hopkins University</span>&nbsp;&nbsp;<span class="author-block"><sup>4</sup>Westlake University</span>&nbsp;&nbsp;<span class="author-block"><sup>5</sup>Zhejiang University</span>
                            <span class="eql-cntrb"><small><br><sup>â€¡</sup>Equal contribution. <sup>*</sup>Corresponding author. </small></span>
                        </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <span class="link-block">
                                    <a href="https://arxiv.org/pdf/2411.17686.pdf" target="_blank"
                                        class="external-link button is-normal is-rounded is-white">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>Paper</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="https://arxiv.org/abs/2411.17686" target="_blank"
                                        class="external-link button is-normal is-rounded is-white">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>arXiv</span>
                                    </a>
                                </span> 
                                <span class="link-block">
                                    <a href="https://huggingface.co/papers/2411.17686" target="_blank"
                                        class="external-link button is-normal is-rounded is-white">
                                        <span class="icon">ðŸ¤—</span>
                                        <span>Paper page</span>
                                    </a>
                                </span>    
                                <span class="link-block">
                                    <a href="https://github.com/kawhiiiileo/FiCoCo" target="_blank"
                                    class="external-link button is-normal is-rounded is-white">
                                    <span class="icon">
                                      <i class="fab fa-github"></i>
                                    </span>
                                    <span>Code</span>
                                  </a>
                                </span>                               
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>
    
    
    <!-- Image carousel -->
    <!-- <section class="hero is-small">
        <div class="hero-body">
            <section class="section" style="padding-top: 0px;">
                <div class="container is-max-desktop">
                    <div class="columns is-centered has-text-centered">
                        <div class="column is-four-fifths">
                            <div class="publication-video-simm">
                                <video width="100%" controls>
                                    <source src="https://cloud.video.taobao.com/play/u/null/p/1/e/6/t/1/439686710798.mp4" type="video/mp4">
                                </video>
                            </div>
                        </div>
                    </div>
                </div>
            </section>
        </div>
    </section> -->
    <!-- End image carousel -->

    <!-- Paper abstract -->
    <section class="section hero is-light">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                            The quadratic complexity of Multimodal Large Language Models (MLLMs) with respect to sequence length poses significant computational and memory challenges, hindering their real-world deployment.
                            While existing training-free token reduction methods aim to address these inefficiencies, how to precisely identify redundant visual tokens and recover the essential information from the discarded tokens remain unclear.
                            In this paper, we propose a ''<b>fi</b>lter-<b>co</b>rrelate-<b>co</b>mpress'' framework that decomposes the token reduction into three stages: <b>filtering</b> redundant tokens, <b>correlating</b> discarded information to preserved tokens, and <b>compressing</b> tokens to minimize redundancy.
                            % resolves critical "what-where-how" questions at each stage
                            Following the framework, we propose a solution <b>FiCoCo</b> to identify limitations in single redundancy assessment, propose adaptive strategies to retain critical information from discarded tokens, and mitigate semantic dilution during token fusion.
                            Two specialized variants, <b>FiCoCo-V</b> (for vision encoders) and <b>FiCoCo-L</b> (for LLM decoders), further optimize efficiency across MLLM architectures.
                            Extensive experiments demonstrate that FiCoCo achieves up to <b>5.7x</b>/<b>14.7x</b> FLOPs reduction with <b>92.8%</b>/<b>93.6%</b> performance retention on LLaVA-1.5-7B/LLaVA-NeXT-7B. 
                            % and scales to video tasks (<b>11.4x</b> FLOPs reduction, <b>92.8%</b> performance retention). 
                            Our methods consistently outperform state-of-the-art training-free approaches, showcasing effectiveness and generalizability across model architectures, sizes, and tasks without requiring retraining.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- End paper abstract -->

    <section class="hero is-small">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <!-- <h2 class="title is-3">Samples generated by <i class="pixart-alpha-icon"></i><span style="color: rgb(72, 87, 220);">Ranni</span></h2> -->  <!-- not used before --> 
                <h2 class="title is-3">Methodology: FiCoCo</h2>
                <img loading="lazy" src="static/images/FiCoCo.png" alt="case" />   
                <p>
                    Based on the paradigm, we develop a series of methods named <b>FiCoCo</b> that efficiently reduce the amount of visual token without re-training.
                    <b>FiCoCo-V</b> reduces tokens in the visual encoder,
                    and <b>FiCoCo-L</b> reduces tokens in the LLM decoder.
                </p>
                <p></p>
                <p>
                    Despite the above figure, we further provide the algorithm illustration for <b>FiCoCo-V</b> and <b>FiCoCo-L</b> to clarify their distinct solutions across three stages.
                </p>            
                <img loading="lazy" src="static/images/algorithm.png" alt="case" />               
            </div>
        </div>
    </section>

    <section class="hero is-small">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <!-- <h2 class="title is-3">Samples generated by <i class="pixart-alpha-icon"></i><span style="color: rgb(72, 87, 220);">Ranni</span></h2> -->  <!-- not used before --> 
                <h2 class="title is-3">Main Results</h2>
                <p>
                    We illustate the average performance of three TFLOPs on six benchmarks, where our <b>FiCoCo-V</b> and <b>FiCoCo-L</b> are significantly superior to other methods, especially when reaching the lowest TFLOPs=1.5:
                </p>
                <img loading="lazy" src="static/images/preformance-FLOPs.png" alt="case" />     
                <p>
                Please refer to our paper for detailed experimental results.
                </p>                        
            </div>
        </div>
    </section>
   

    <!--BibTex citation -->
    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            <pre><code>@article{FiCoCo2024,
    title={Filter, Correlate, Compress: Training-Free Token Reduction for MLLM Acceleration}, 
    author={Yuhang Han and Xuyang Liu and Zihan Zhang and Pengxiang Ding and Donglin Wang and Honggang Chen and Qingsen Yan and Siteng Huang},
    year={2024},
    eprint={2411.17686},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}</code></pre>             
        </div>
    </section>
    <!--End BibTex citation -->


    <footer class="footer">
        <div class="container">
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">
                        <p>
                            This page was built using the <a
                                href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                                target="_blank">Academic Project Page Template</a> which was adopted from the <a
                                href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
                            You are free to borrow the of this website, we just ask that you link back to this page in
                            the footer. <br> This website is licensed under a <a rel="license"
                                href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                                Commons Attribution-ShareAlike 4.0 International License</a>.
                        </p>
                        <p class="has-text-centered">Total clicks: <span id="busuanzi_value_site_pv"></span></p>
                    </div>
                </div>
            </div>
        </div>
    </footer>

</body>

</html>
